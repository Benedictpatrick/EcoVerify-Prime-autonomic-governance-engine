{
  "version": "2026-v2",
  "jurisdiction": "European Union",
  "effective_date": "2026-02-01",
  "articles": [
    {
      "section": "Article 1",
      "title": "Subject Matter and Scope",
      "text": "This Regulation lays down harmonised rules on artificial intelligence, including prohibitions of certain AI practices, requirements for high-risk AI systems, transparency obligations for certain AI systems, and rules on market surveillance and governance.",
      "keywords": ["scope", "harmonised rules", "governance"]
    },
    {
      "section": "Article 3",
      "title": "Definitions",
      "text": "AI system means a machine-based system designed to operate with varying levels of autonomy, that may exhibit adaptiveness after deployment and that infers how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments.",
      "keywords": ["definition", "AI system", "autonomy", "adaptiveness"]
    },
    {
      "section": "Article 5",
      "title": "Prohibited Artificial Intelligence Practices",
      "text": "The following AI practices shall be prohibited: (a) AI systems that deploy subliminal techniques beyond a person's consciousness to materially distort behaviour; (b) AI systems that exploit vulnerabilities of specific groups; (c) social scoring by public authorities; (d) real-time remote biometric identification in publicly accessible spaces for law enforcement (subject to exceptions).",
      "keywords": ["prohibited", "subliminal", "social scoring", "biometric", "unacceptable risk"]
    },
    {
      "section": "Article 6",
      "title": "Classification Rules for High-Risk AI Systems",
      "text": "An AI system shall be considered high-risk where it is used as a safety component of a product covered by Union harmonisation legislation, or the AI system itself is a product covered by such legislation, and is required to undergo third-party conformity assessment. AI systems in Annex III areas (critical infrastructure, education, employment, essential services, law enforcement, migration, justice) are also high-risk.",
      "keywords": ["high-risk", "classification", "safety component", "critical infrastructure", "conformity"]
    },
    {
      "section": "Article 9",
      "title": "Risk Management System",
      "text": "A risk management system shall be established, implemented, documented and maintained for high-risk AI systems. It shall comprise a continuous iterative process planned and run throughout the lifecycle, consisting of: identification and analysis of known and foreseeable risks; estimation and evaluation of risks that may emerge; evaluation of other risks based on post-market monitoring data; adoption of appropriate risk management measures.",
      "keywords": ["risk management", "lifecycle", "continuous", "post-market monitoring"]
    },
    {
      "section": "Article 10",
      "title": "Data and Data Governance",
      "text": "High-risk AI systems which make use of techniques involving the training of AI models with data shall be developed on the basis of training, validation and testing data sets that meet quality criteria. Data governance and management practices shall address data collection, data preparation, formulation of assumptions, prior assessment of availability, quantity and suitability of data sets, examination for biases, and identification of data gaps.",
      "keywords": ["data governance", "training data", "quality", "bias", "data gaps"]
    },
    {
      "section": "Article 11",
      "title": "Technical Documentation",
      "text": "The technical documentation of a high-risk AI system shall be drawn up before that system is placed on the market and kept up to date. It shall demonstrate compliance with the requirements set out in this chapter.",
      "keywords": ["documentation", "compliance", "technical"]
    },
    {
      "section": "Article 12",
      "title": "Record-Keeping and Logging",
      "text": "High-risk AI systems shall technically allow for the automatic recording of events (logs) over the lifetime of the system. Logging capabilities shall ensure traceability of the AI system's functioning, including identification of input data, timestamp, reference ID, and the natural persons involved in the verification of results.",
      "keywords": ["logging", "traceability", "record-keeping", "audit trail"]
    },
    {
      "section": "Article 13",
      "title": "Transparency and Provision of Information to Deployers",
      "text": "High-risk AI systems shall be designed and developed in such a way as to ensure that their operation is sufficiently transparent to enable deployers to interpret a system's output and use it appropriately. An appropriate type and degree of transparency shall be ensured, to allow deployers and authorities to fulfil obligations. Instructions for use shall include: characteristics, capabilities & limitations of the system; intended purpose; measures of accuracy; foreseeable misuse risks; human oversight measures.",
      "keywords": ["transparency", "interpretability", "instructions", "deployer", "accuracy"]
    },
    {
      "section": "Article 14",
      "title": "Human Oversight",
      "text": "High-risk AI systems shall be designed and developed so as to be effectively overseen by natural persons during the period in which they are in use. Human oversight measures shall be identified and built into the system or implemented by the deployer. Measures shall enable individuals to: fully understand the capacities and limitations of the high-risk AI system; monitor its operation; be able to decide not to use the system or to disregard, override or reverse its output; intervene or interrupt the system through a 'stop' button or similar procedure.",
      "keywords": ["human oversight", "intervention", "stop button", "override", "HITL", "human-in-the-loop"]
    },
    {
      "section": "Article 15",
      "title": "Accuracy, Robustness and Cybersecurity",
      "text": "High-risk AI systems shall be designed and developed in such a way that they achieve an appropriate level of accuracy, robustness, and cybersecurity, and perform consistently in those respects throughout their lifecycle. Levels of accuracy and relevant metrics shall be declared in accompanying instructions of use. Systems shall be resilient regarding errors, faults or inconsistencies.",
      "keywords": ["accuracy", "robustness", "cybersecurity", "resilience", "metrics"]
    },
    {
      "section": "Article 26",
      "title": "Obligations of Deployers of High-Risk AI Systems",
      "text": "Deployers of high-risk AI systems shall use such systems in accordance with instructions of use; assign human oversight to natural persons who have the necessary competence, training and authority; ensure that input data is relevant and sufficiently representative in view of the intended purpose; monitor the operation of the high-risk AI system on the basis of instructions of use.",
      "keywords": ["deployers", "obligations", "human oversight", "monitoring", "competence"]
    },
    {
      "section": "Article 52",
      "title": "Transparency Obligations for Certain AI Systems",
      "text": "Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that the natural person is informed that they are interacting with an AI system, unless this is obvious. Users of AI systems that generate or manipulate content (deep fakes) shall disclose that the content has been artificially generated or manipulated. This obligation shall not apply where the use is authorised by law or where content obviously pertains to artistic, satirical, or fictional work.",
      "keywords": ["transparency", "disclosure", "deep fakes", "interaction", "notification"]
    },
    {
      "section": "Article 72",
      "title": "Post-Market Monitoring by Providers",
      "text": "Providers shall establish and document a post-market monitoring system in a manner that is proportionate to the nature of the AI technologies and the risks of the high-risk AI system. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data which may be provided by deployers or which may be collected through other sources.",
      "keywords": ["post-market", "monitoring", "data collection", "systematic"]
    },
    {
      "section": "Article 83",
      "title": "AI Regulatory Sandboxes",
      "text": "AI regulatory sandboxes established by national competent authorities shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific sandbox plan agreed between the providers or prospective providers and the competent authority.",
      "keywords": ["sandbox", "testing", "innovation", "controlled environment"]
    }
  ]
}
